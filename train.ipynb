{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0f3040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from data_preprocess import SpeechDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from time import time\n",
    "from torch.nn import Softmax\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from random import choice\n",
    "from model import ResModel\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d68ec6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "def get_time(now, start):\n",
    "    time_in_min = int((now - start) / 60)\n",
    "    return time_in_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ada6239",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32  # 데이터 묶음에 해당하는 batch_size는 GPU 메모리에 알맞게 지정한다\n",
    "mGPU = False  # multi-GPU를 사용할 경우에는 True로 지정한다\n",
    "epochs = 20  # 모델이 훈련 데이터를 학습하는 횟수를 지정한다\n",
    "mode = 'cv' # 교차 검증 모드(cv) or 테스트 모드(test)\n",
    "model_name = 'model/model_resnet.pth'  # 모델 결과물을 저장할 때 모델 이름을 지정한다\n",
    "\n",
    "# ResNet 모델을 활성화한다\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "model = ResModel\n",
    "speechmodel = torch.nn.DataParallel(model()) if mGPU else model()\n",
    "speechmodel = speechmodel.cuda()\n",
    "\n",
    "# SpeechDataset을 활성화한다\n",
    "labels = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n",
    "label_to_int = dict(zip(labels, range(len(labels))))\n",
    "int_to_label = dict(zip(range(len(labels)), labels))\n",
    "int_to_label.update({len(labels): 'unknown', len(labels) + 1: 'silence'})\n",
    "\n",
    "# 모드에 따라 학습 및 검증에 사용할 파일을 선택한다\n",
    "trn = 'input/trn.txt' if mode == 'cv' else 'input/trn_all.txt'\n",
    "tst = 'input/val.txt' if mode == 'cv' else 'input/tst.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f636b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = [line.strip() for line in open(trn, 'r').readlines()]\n",
    "wav_list = [line.split(',')[-1] for line in trn]\n",
    "label_list = [line.split(',')[0] for line in trn]\n",
    "# 학습용 SpeechDataset을 불러온다\n",
    "traindataset = SpeechDataset(mode='train', label_to_int=label_to_int, wav_list=wav_list, label_list=label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e75bb1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/989 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/989 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 1.95 GiB total capacity; 1.07 GiB already allocated; 3.94 MiB free; 1.07 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-75b608934e52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# 현재 모델의 예측값(y_pred)을 계산한다\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspeechmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred_labels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/바탕화면/kaggle/kaggle/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"conv{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mold_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    393\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 395\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    396\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 1.95 GiB total capacity; 1.07 GiB already allocated; 3.94 MiB free; 1.07 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "for e in range(epochs):\n",
    "    print(\"training epoch \", e)\n",
    "    # learning_rate를 epoch마다 다르게 지정한다\n",
    "    learning_rate = 0.01 if e < 10 else 0.001\n",
    "    optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, speechmodel.parameters()), lr=learning_rate, momentum=0.9, weight_decay=0.00001)\n",
    "    # 모델을 학습하기 위하여 .train() 함수를 실행한다\n",
    "    speechmodel.train()\n",
    "\n",
    "    total_correct = 0\n",
    "    num_labels = 0\n",
    "    trainloader = DataLoader(traindataset, BATCH_SIZE, shuffle=True)\n",
    "    # 학습을 수행한다\n",
    "    for batch_idx, batch_data in enumerate(tqdm(trainloader)):\n",
    "        # batch_size 만큼의 음성 데이터(spec)와 정답값(label)을 받아온다\n",
    "        spec = batch_data['spec']\n",
    "        label = batch_data['label']\n",
    "        spec, label = Variable(spec.cuda()), Variable(label.cuda())\n",
    "        # 현재 모델의 예측값(y_pred)을 계산한다\n",
    "        y_pred = speechmodel(spec)\n",
    "        _, pred_labels = torch.max(y_pred.data, 1)\n",
    "        correct = (pred_labels == label.data).sum()\n",
    "        # 정답과 예측값간의 차이(loss)를 계산한다 \n",
    "        loss = loss_fn(y_pred, label)\n",
    "\n",
    "        total_correct += correct\n",
    "        num_labels += len(label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # loss를 기반으로 back-propagation을 수행한다\n",
    "        loss.backward()\n",
    "        # 모델 파라미터를 업데이트한다. (실질적 학습)\n",
    "        optimizer.step()\n",
    "\n",
    "    # 훈련 데이터에서의 정확률을 기록한다\n",
    "    print(\"training accuracy:\", 100. * total_correct / num_labels, get_time(time(), start_time))\n",
    "\n",
    "    # 교차 검증 모드의 경우, 검증 데이터에 대한 정확률을 기록한다\n",
    "    if mode == 'cv':\n",
    "        # 현재 학습 중인 모델을 임시로 저장한다\n",
    "        torch.save(speechmodel.state_dict(), '{}_cv'.format(model_name))\n",
    "\n",
    "        # 검증 데이터를 불러온다\n",
    "        softmax = Softmax()\n",
    "        tst_list = [line.strip() for line in open(tst, 'r').readlines()]\n",
    "        wav_list = [line.split(',')[-1] for line in tst_list]\n",
    "        label_list = [line.split(',')[0] for line in tst_list]\n",
    "        cvdataset = SpeechDataset(mode='test', label_to_int=label_to_int, wav_list=wav_list)\n",
    "        cvloader = DataLoader(cvdataset, BATCH_SIZE, shuffle=False)\n",
    "\n",
    "        # 모델을 불러와 .eval() 함수로 검증 준비를 한다\n",
    "        speechmodel = torch.nn.DataParallel(model()) if mGPU else model()\n",
    "        speechmodel.load_state_dict(torch.load('{}_cv'.format(model_name)))\n",
    "        speechmodel = speechmodel.cuda()\n",
    "        speechmodel.eval()\n",
    "\n",
    "        # 검증 데이터를 batch_size만큼씩 받아오며 예측값을 저장한다\n",
    "        fnames, preds = [], []\n",
    "        for batch_idx, batch_data in enumerate(tqdm(cvloader)):\n",
    "            spec = Variable(batch_data['spec'].cuda())\n",
    "            fname = batch_data['id']\n",
    "            y_pred = softmax(speechmodel(spec))\n",
    "            preds.append(y_pred.data.cpu().numpy())\n",
    "            fnames += fname\n",
    "\n",
    "        preds = np.vstack(preds)\n",
    "        preds = [int_to_label[x] for x in np.argmax(preds, 1)]\n",
    "        fnames = [fname.split('/')[-2] for fname in fnames]\n",
    "        num_correct = 0\n",
    "        for true, pred in zip(fnames, preds):\n",
    "            if true == pred:\n",
    "                num_correct += 1\n",
    "\n",
    "        # 검증 데이터의 정확률을 기록한다\n",
    "        print(\"cv accuracy:\", 100. * num_correct / len(preds), get_time(time(), start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "374d4dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing prediction...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'input/val.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7cb1307d947d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 테스트 데이터를 불러온다\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mwav_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtst\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtestdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpeechDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_to_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_to_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwav_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwav_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'input/val.txt'"
     ]
    }
   ],
   "source": [
    "create_directory(\"model\")\n",
    "torch.save(speechmodel.state_dict(), model_name)\n",
    "\n",
    "# 테스트 데이터에 대한 예측값을 파일에 저장한다\n",
    "print(\"doing prediction...\")\n",
    "softmax = Softmax()\n",
    "\n",
    "# 테스트 데이터를 불러온다\n",
    "tst = [line.strip() for line in open(tst, 'r').readlines()]\n",
    "wav_list = [line.split(',')[-1] for line in tst]\n",
    "testdataset = SpeechDataset(mode='test', label_to_int=label_to_int, wav_list=wav_list)\n",
    "testloader = DataLoader(testdataset, BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# 모델을 불러온다\n",
    "speechmodel = torch.nn.DataParallel(model()) if mGPU else model()\n",
    "speechmodel.load_state_dict(torch.load(model_name))\n",
    "speechmodel = speechmodel.cuda()\n",
    "speechmodel.eval()\n",
    "\n",
    "test_fnames, test_labels = [], []\n",
    "pred_scores = []\n",
    "\n",
    "# 테스트 데이터에 대한 예측값을 계산한다\n",
    "for batch_idx, batch_data in enumerate(tqdm(testloader)):\n",
    "    spec = Variable(batch_data['spec'].cuda())\n",
    "    fname = batch_data['id']\n",
    "    y_pred = softmax(speechmodel(spec))\n",
    "    pred_scores.append(y_pred.data.cpu().numpy())\n",
    "    test_fnames += fname\n",
    "\n",
    "# 가장 높은 확률값을 가진 예측값을 label 형태로 저장한다\n",
    "final_pred = np.vstack(pred_scores)\n",
    "final_labels = [int_to_label[x] for x in np.argmax(final_pred, 1)]\n",
    "test_fnames = [x.split(\"/\")[-1] for x in test_fnames]\n",
    "\n",
    "# 테스트 파일 명과 예측값을 sub 폴더 아래 저장한다. 캐글에 직접 업로드 할 수 있는 파일 포맷이다.\n",
    "create_directory(\"sub\")\n",
    "pd.DataFrame({'fname': test_fnames, 'label': final_labels}).to_csv(\"sub/{}.csv\".format(model_name.split('/')[-1]), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d879a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13631782",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05c3f45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
